{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "<br />\n",
    "<p align=\"center\">\n",
    "  <img src=\"../images/dtlogo.png\" alt=\"Logo\" width=\"111\" height=\"100\">\n",
    "\n",
    "  <h1 align=\"center\">Object detection for robots</h1>\n",
    "</p>\n",
    "\n",
    "\n",
    "## Integration\n",
    "\n",
    "Finally, you need to integrate your model with ROS. You will edit the object detection node found in `src/object_detection/src`.\n",
    "\n",
    "If you don't have a Jetson Nano Duckiebot, you can run this exercise locally. This will run your code as a pytorch model\n",
    "\n",
    "If you have a Jetson Nano Duckiebot, you can run this exercise on your Duckiebot. This will convert your model to a TensorRT model, and run it your Jetson Nano's GPU.\n",
    "\n",
    "In both cases, you need to edit the ROS node to decide how you will use the detections. Should you call your model on every image from your camera? Only once every 4-5 frames, to preserve your CPU? You might also want to change your robot's behaviour depending on the size of the detection. If it is small, the object is probably far away, so there's no need to stop.\n",
    "\n",
    "TODO: what should they do to get started? We will walk through each function that they should modify step by step\n",
    "\n",
    "\n",
    "### Framerate\n",
    "\n",
    "While object detection is useful, it is also very expensive, computationally.\n",
    "\n",
    "One trick used to reduce said cost is to only call the full model infrequently.\n",
    "For example, one might call the model only every second, which is very slow in\n",
    "computer timeframes, but relatively fast for the real world. Odds are that the detections\n",
    "obtained every second will look very similar.\n",
    "\n",
    "Of course, this varies from application to application. In very dynamic, fast\n",
    "robotic environments, clearly the model should be called more frequently.\n",
    "\n",
    "You can fine-tune this yourself: the function bellow indicates the number of frames\n",
    "your robot should skip before calling its object detection model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def NUMBER_FRAMES_SKIPPED():\n",
    "    # todo change this number to drop more frames\n",
    "    # (must be a positive integer)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In real life, we would use a full neural network model to produce very accurate\n",
    "predictions, and then a less accurate model coupled with a Kalman filter (or\n",
    "other such estimation system) to \"track\" each prediction during the skipped frames.\n",
    "\n",
    "For this exercises, we will limit ourselves to just skipping frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "\n",
    "Some of your predictions might not actually be useful. For example, in Duckietown,\n",
    "the trucks and busses are always parked on the side of the road. Your robot will\n",
    "never have to avoid or stop for them.\n",
    "\n",
    "Cones can be in the road in some maps, but for this exercises, you can assume that there\n",
    "aren't any.\n",
    "\n",
    "#### Filtering by class\n",
    "\n",
    "For this reason, you probably want to remove all non-duckies from your predictions,\n",
    "since only duckies will be on the road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# `class` is the class of a prediction\n",
    "def filter_by_classes(clas):\n",
    "    # Right now, this returns True for every object's class\n",
    "    # Change this to only return True for duckies!\n",
    "    # In other words, returning False means that this prediction is ignored.\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Filtering by score\n",
    "\n",
    "Depending on the model, you might also want to remove very unconfident detections.\n",
    "\n",
    "Then again, your model might not be confident even for detections that are absolutely\n",
    "correct. You should experiment to find a value that works well for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# `scor` is the confidence score of a prediction\n",
    "def filter_by_scores(scor):\n",
    "    # Right now, this returns True for every object's confidence\n",
    "    # Change this to filter the scores, or not at all\n",
    "    # (returning True for all of them might be the right thing to do!)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Filtering by bounding box\n",
    "\n",
    "Finally, you should also evaluate what each detection *means* in terms of positionning.\n",
    "\n",
    "If a bounding box is in the leftmost or rightmost thirds of the image, it might be the case that\n",
    "the object in not even on the road, and that your robot would be able to go by it without issue.\n",
    "\n",
    "![image of a bounding box](../images/thirds.png)\n",
    "\n",
    "Also, if a bounding box's area is small, its object is likely far away. So there is no need to\n",
    "try to avoid the object or stop the robot: the robot still has a bit of driving to do before it reaches\n",
    "the object. So filtering out small detections might be a good idea too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# `bbox` is the bounding box of a prediction, in xyxy format\n",
    "# So it is of the shape (leftmost x pixel, topmost y pixel, rightmost x pixel, bottommost y pixel)\n",
    "def filter_by_bboxes(bbox):\n",
    "    # Like in the other cases, return False if the bbox should not be considered.\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Fine-tuning\n",
    "\n",
    "In all of the functions above, there is not objective right answer. You should play with\n",
    "your functions and fine-tune their behaviours. Robotics is an iterative process!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
